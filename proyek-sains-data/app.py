import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, RTCConfiguration, WebRtcMode
import numpy as np
import joblib
import librosa
import os
import av
import soundfile as sf
from pydub import AudioSegment
import threading
import logging

# Setup logging untuk debug
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# ===============================
# ğŸ”¹ Judul & Deskripsi
# ===============================
st.title("ğŸ™ï¸ Voice Command Classifier: BUKA / TUTUP")
st.write("Pilih salah satu metode di bawah untuk memberikan input suara:")

# ===============================
# ğŸ”¹ Load Model & Scaler
# ===============================
model_path = os.path.join(os.path.dirname(__file__), "model_knn_voice.pkl")
scaler_path = os.path.join(os.path.dirname(__file__), "scaler.pkl")

model = joblib.load(model_path)
scaler = joblib.load(scaler_path)

# ===============================
# ğŸ”¹ Konfigurasi WebRTC
# ===============================
rtc_config = RTCConfiguration({
    "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
})

# ===============================
# ğŸ”¹ Pilihan Metode Input
# ===============================
mode = st.radio("ğŸ§ Pilih metode input suara:", ["ğŸ™ï¸ Rekam langsung", "ğŸ“ Upload file (.wav / .mp3)"])

# ===============================
# 1ï¸âƒ£ MODE REKAM LANGSUNG
# ===============================
if mode == "ğŸ™ï¸ Rekam langsung":
    st.info("1ï¸âƒ£ Tekan **START** â†’ 2ï¸âƒ£ Ucapkan 'BUKA' atau 'TUTUP' 2-3 detik â†’ 3ï¸âƒ£ Tekan **STOP** â†’ 4ï¸âƒ£ Klik **Analisis Voice**")
    
    # Audio Processor dengan debugging
    class AudioProcessor(AudioProcessorBase):
        def __init__(self):
            self.frames = []
            self.lock = threading.Lock()
            self.sample_rate = 48000
            self.frame_count = 0
            logger.info("AudioProcessor initialized")
            
        def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
            try:
                self.frame_count += 1
                
                # Log setiap 50 frames
                if self.frame_count % 50 == 0:
                    logger.info(f"Received frame #{self.frame_count}")
                
                # Konversi frame ke numpy array
                sound = frame.to_ndarray()
                
                # Debug info pertama kali
                if self.frame_count == 1:
                    logger.info(f"First frame - shape: {sound.shape}, dtype: {sound.dtype}, format: {frame.format.name}, layout: {frame.layout.name}")
                
                # PENTING: PyAV mengembalikan array dengan shape (channels, samples)
                # Kita perlu transpose jika channels ada di axis 0
                if len(sound.shape) == 2:
                    # Jika shape (2, 480) -> transpose ke (480, 2) lalu rata-rata
                    if sound.shape[0] < sound.shape[1]:
                        sound = sound.T  # Transpose
                    # Konversi ke mono dengan rata-rata channels
                    sound = sound.mean(axis=1)
                elif len(sound.shape) == 1:
                    # Sudah mono
                    pass
                else:
                    logger.warning(f"Unexpected shape: {sound.shape}")
                
                # Pastikan 1D array
                sound = sound.flatten().astype(np.float32)
                
                # Thread-safe append
                with self.lock:
                    self.frames.append(sound)
                
                return frame
            except Exception as e:
                logger.error(f"Error in recv: {e}")
                import traceback
                logger.error(traceback.format_exc())
                return frame
        
        def get_frames(self):
            with self.lock:
                return self.frames.copy()
        
        def get_total_samples(self):
            with self.lock:
                return sum(len(f) for f in self.frames)
        
        def get_frame_count(self):
            return self.frame_count
        
        def clear_frames(self):
            with self.lock:
                self.frames = []
                self.frame_count = 0

    # WebRTC Streamer dengan konfigurasi lebih eksplisit
    ctx = webrtc_streamer(
        key="voice-cmd-v2",  # Ganti key untuk reset
        mode=WebRtcMode.SENDRECV,
        audio_processor_factory=AudioProcessor,
        rtc_configuration=rtc_config,
        media_stream_constraints={
            "audio": {
                "echoCancellation": True,
                "noiseSuppression": True,
                "autoGainControl": True,
            },
            "video": False
        },
        async_processing=True,
    )

    # Debug info
    with st.expander("ğŸ› Debug Info", expanded=True):
        st.write(f"**WebRTC State:** {ctx.state}")
        st.write(f"**Playing:** {ctx.state.playing}")
        st.write(f"**Audio Processor exists:** {ctx.audio_processor is not None}")
        
        if ctx.audio_processor:
            st.write(f"**Frame count (internal):** {ctx.audio_processor.get_frame_count()}")
            st.write(f"**Frames list length:** {len(ctx.audio_processor.get_frames())}")
            st.write(f"**Total samples:** {ctx.audio_processor.get_total_samples()}")

    # Status dan monitoring
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if ctx.state.playing:
            st.success("ğŸ”´ **MEREKAM**")
        else:
            st.info("âšª Tidak merekam")
    
    with col2:
        if ctx.audio_processor:
            total_samples = ctx.audio_processor.get_total_samples()
            duration = total_samples / 48000
            st.metric("Durasi", f"{duration:.2f}s")
        else:
            st.metric("Durasi", "0.00s")
    
    with col3:
        if ctx.audio_processor:
            frame_count = len(ctx.audio_processor.get_frames())
            st.metric("Frames", frame_count)
        else:
            st.metric("Frames", 0)
    
    # Auto-refresh untuk update real-time
    if ctx.state.playing:
        import time
        time.sleep(0.1)
        st.rerun()
    
    # Progress bar
    if ctx.audio_processor:
        duration = ctx.audio_processor.get_total_samples() / 48000
        min_duration = 1.0
        progress = min(duration / min_duration, 1.0)
        st.progress(progress)
        
        if duration < min_duration and ctx.state.playing:
            st.warning(f"â³ Rekam minimal {min_duration:.0f} detik. Sekarang: {duration:.2f} detik")
        elif duration >= min_duration:
            st.success(f"âœ… Audio cukup! Tekan STOP lalu klik Analisis Voice")
    
    # Troubleshooting tips
    if ctx.state.playing and ctx.audio_processor and ctx.audio_processor.get_frame_count() == 0:
        st.error("âš ï¸ TIDAK ADA FRAME MASUK! Coba:")
        st.write("1. Refresh halaman (F5)")
        st.write("2. Pastikan mikrofon tidak digunakan aplikasi lain")
        st.write("3. Cek browser console (F12) untuk error")
        st.write("4. Coba browser lain (Chrome/Edge)")
        st.write("5. Pastikan akses mikrofon diizinkan (klik ikon gembok di address bar)")
    
    # Tombol kontrol
    col_btn1, col_btn2 = st.columns(2)
    
    with col_btn1:
        if st.button("ğŸ”„ Clear Buffer"):
            if ctx.audio_processor:
                ctx.audio_processor.clear_frames()
                st.rerun()
    
    with col_btn2:
        can_analyze = (ctx.audio_processor and 
                      ctx.audio_processor.get_total_samples() > 0 and
                      not ctx.state.playing)
        
        analyze_clicked = st.button(
            "ğŸ” Analisis Voice", 
            disabled=not can_analyze,
            type="primary"
        )
    
    # Proses analisis
    if analyze_clicked and ctx.audio_processor:
        frames = ctx.audio_processor.get_frames()
        
        if len(frames) == 0:
            st.error("âŒ Tidak ada audio! Troubleshooting:")
            st.write("âœ“ Apakah tombol START sudah ditekan?")
            st.write("âœ“ Apakah ada tulisan 'MEREKAM' berwarna hijau?")
            st.write("âœ“ Apakah browser meminta izin mikrofon?")
            st.write("âœ“ Apakah Frame count > 0 saat merekam?")
        else:
            try:
                with st.spinner("ğŸ”„ Memproses audio..."):
                    # Gabungkan frames
                    audio_data = np.concatenate(frames)
                    original_sr = 48000
                    
                    duration = len(audio_data) / original_sr
                    st.info(f"ğŸ“Š Audio terekam: {duration:.2f} detik ({len(audio_data)} samples, {len(frames)} frames)")
                    
                    # Resample ke 16kHz
                    target_sr = 16000
                    audio_resampled = librosa.resample(
                        audio_data, 
                        orig_sr=original_sr, 
                        target_sr=target_sr
                    )
                    
                    # Normalisasi
                    audio_resampled = audio_resampled / (np.max(np.abs(audio_resampled)) + 1e-8)
                    
                    # Simpan dan tampilkan
                    sf.write("recorded_audio.wav", audio_resampled, target_sr)
                    st.audio("recorded_audio.wav", format="audio/wav")
                    
                    # Trim silence
                    audio_trimmed, _ = librosa.effects.trim(audio_resampled, top_db=20)
                    st.write(f"âœ‚ï¸ Setelah trim: {len(audio_trimmed)/target_sr:.2f} detik")
                    
                    if len(audio_trimmed) < 0.3 * target_sr:
                        st.warning("âš ï¸ Audio terlalu pendek setelah trim. Mungkin hanya noise. Coba ucapkan lebih keras.")
                    else:
                        # Ekstraksi MFCC
                        mfcc = librosa.feature.mfcc(y=audio_trimmed, sr=target_sr, n_mfcc=13)
                        features = np.mean(mfcc.T, axis=0).reshape(1, -1)
                        
                        st.write(f"ğŸ” MFCC shape: {mfcc.shape}")
                        
                        # Prediksi
                        features_scaled = scaler.transform(features)
                        pred = model.predict(features_scaled)
                        
                        result = "BUKA" if pred[0] == 0 else "TUTUP"
                        
                        # Tampilkan hasil
                        st.success(f"# ğŸ§ Prediksi: **{result}**")
                        
                        # Coba ambil confidence
                        try:
                            proba = model.predict_proba(features_scaled)
                            confidence = np.max(proba) * 100
                            st.info(f"**Confidence:** {confidence:.1f}%")
                            
                            with st.expander("ğŸ“Š Detail Probabilitas"):
                                st.write(f"- BUKA: {proba[0][0]*100:.1f}%")
                                st.write(f"- TUTUP: {proba[0][1]*100:.1f}%")
                        except:
                            pass
                        
                        # Clear buffer setelah analisis
                        ctx.audio_processor.clear_frames()
                    
            except Exception as e:
                st.error(f"âŒ Error: {str(e)}")
                import traceback
                with st.expander("ğŸ› Debug Info"):
                    st.code(traceback.format_exc())

# ===============================
# 2ï¸âƒ£ MODE UPLOAD FILE
# ===============================
else:
    uploaded_file = st.file_uploader("ğŸ“ Upload file suara (.wav / .mp3)", type=["wav", "mp3"])

    if uploaded_file is not None:
        temp_path = "uploaded_audio.wav"

        # Konversi MP3 â†’ WAV jika perlu
        if uploaded_file.type == "audio/mpeg":
            audio = AudioSegment.from_mp3(uploaded_file)
            audio.export(temp_path, format="wav")
        else:
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.read())

        st.audio(temp_path, format="audio/wav")

        if st.button("ğŸ” Analisis Voice", type="primary"):
            try:
                y, sr = librosa.load(temp_path, sr=16000)
                
                st.info(f"ğŸ“Š Durasi: {len(y)/sr:.2f} detik")
                
                # Normalisasi
                y = y / (np.max(np.abs(y)) + 1e-8)
                
                # Trim
                y_trimmed, _ = librosa.effects.trim(y, top_db=20)
                
                # MFCC
                mfcc = librosa.feature.mfcc(y=y_trimmed, sr=sr, n_mfcc=13)
                features = np.mean(mfcc.T, axis=0).reshape(1, -1)
                features_scaled = scaler.transform(features)
                
                # Prediksi
                pred = model.predict(features_scaled)
                result = "BUKA" if pred[0] == 0 else "TUTUP"
                
                st.success(f"# ğŸ§ Prediksi: **{result}**")
                
                try:
                    proba = model.predict_proba(features_scaled)
                    confidence = np.max(proba) * 100
                    st.info(f"**Confidence:** {confidence:.1f}%")
                    
                    with st.expander("ğŸ“Š Detail"):
                        st.write(f"- BUKA: {proba[0][0]*100:.1f}%")
                        st.write(f"- TUTUP: {proba[0][1]*100:.1f}%")
                except:
                    pass
                
            except Exception as e:
                st.error(f"âŒ Error: {str(e)}")